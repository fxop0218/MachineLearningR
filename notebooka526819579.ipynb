{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"dataset = read.delim(\"../input/restaurant-reviews/Restaurant_Reviews.tsv\", quote = \"\", stringsAsFactors = FALSE)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-12T16:42:06.114568Z","iopub.execute_input":"2022-09-12T16:42:06.115954Z","iopub.status.idle":"2022-09-12T16:42:06.135042Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Limpieza de datos","metadata":{}},{"cell_type":"code","source":"#install.packages(\"tm\")ç\n#install.packages(\"SnowballC\") # Instalación para qu elas stopwords funcionesnn\nlibrary(tm)\nlibrary(SnowballC)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T16:42:06.137855Z","iopub.execute_input":"2022-09-12T16:42:06.140994Z","iopub.status.idle":"2022-09-12T16:42:06.156762Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"corpus = VCorpus(VectorSource(dataset$Liked)) # Create corpus\ncorpus = tm_map(corpus, content_transformer(tolower)) # Transform to lower case\n# as.character(corpus[[1]])\ncorpus = tm_map(corpus, removeNumbers) # Delete number\ncorpus = tm_map(corpus, removePunctuation) # Delete puntuation\ncorpus = tm_map(corpus, removeWords, stopwords(kind = \"en\")) # Eliminan las stopwords (Palabras sin relevancia)\ncorpus = tm_map(corpus, stemDocument) # Transforma una palabra derivada en la mas simple loving = love\ncorpus = tm_map(corpus, stripWhitespace)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T16:42:06.159178Z","iopub.execute_input":"2022-09-12T16:42:06.160965Z","iopub.status.idle":"2022-09-12T16:42:06.768299Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Create model Bag of words\n","metadata":{}},{"cell_type":"code","source":"dtm = DocumentTermMatrix(corpus) # Creación de matriz dispersa\ndtm = removeSparseTerms(dtm, 0.99) # Eliminar palabras que solo salen una vez","metadata":{"execution":{"iopub.status.busy":"2022-09-12T16:42:06.770347Z","iopub.execute_input":"2022-09-12T16:42:06.771547Z","iopub.status.idle":"2022-09-12T16:42:06.888555Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"dataset$Liked = factor(dataset$Liked, levels = c(0,1))","metadata":{"execution":{"iopub.status.busy":"2022-09-12T16:42:06.890580Z","iopub.execute_input":"2022-09-12T16:42:06.891687Z","iopub.status.idle":"2022-09-12T16:42:06.901141Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"library(caTools)\nset.seed(123)\nsplit <- sample.split(dataset$Liked, SplitRatio = 0.8)\n\ntrain_set = subset(dataset, split == TRUE)\ntest_set = subset(dataset, split == FALSE)\n\n# Creación del modelo random forest\nlibrary(randomForest)\nclassifier = randomForest(x = train_set[,-692],\n                          y = train_set$Liked,\n                          ntree = 10)\n\n\ny_pred = predict(classifier, newdata = test_set[,692]) # Pasa de mostrate probabilidad a ponerte el mas probeble que\n# Crear matriz de confusión\n\ncm <- table(test_set[,3], y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T16:42:06.903181Z","iopub.execute_input":"2022-09-12T16:42:06.904379Z","iopub.status.idle":"2022-09-12T16:42:06.954347Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}